{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PujanPandey07/Movie-Recommender-system-using-NLP-and-ML/blob/main/finalsystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bea3fJIKXpAk"
      },
      "source": [
        "## code to create a simple ui based recommender system using streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9eCTrqJX3TE"
      },
      "source": [
        "## trained logistic regression model,trained tfidf vectorizer and dataset with vector embeddings are saved in my drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw6GjjkvhfVF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADiJejyvhh_S",
        "outputId": "e421816c-f3b3-49cd-c804-32cdf033dfd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvAR4VhpTRMF",
        "outputId": "1edc2abb-fa81-45a6-f019-5da7b5ccbe3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.47.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.47.0 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lCSxpbTTWm7",
        "outputId": "0533bffd-324e-439d-9f88-cd574918d670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting thefuzz\n",
            "  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, thefuzz\n",
            "Successfully installed rapidfuzz-3.13.0 thefuzz-0.22.1\n"
          ]
        }
      ],
      "source": [
        "!pip install thefuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYZKj3YWTMra",
        "outputId": "491f1003-2098-4789-f6ea-531027d83168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\n",
            "changed 22 packages in 1s\n",
            "\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kyour url is: https://tiny-animals-sing.loca.lt\n",
            "/tools/node/lib/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:10407 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/tools/node/lib/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (node:events:524:28)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (node:internal/streams/destroy:169:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (node:internal/streams/destroy:128:3)\u001b[39m\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\u001b[39m\n",
            "\n",
            "Node.js v20.19.0\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q streamlit thefuzz scikit-learn pandas numpy joblib\n",
        "!npm install -g localtunnel\n",
        "\n",
        "# Create the Streamlit app file\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write('''\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from thefuzz import process\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from joblib import load\n",
        "import warnings\n",
        "\n",
        "# Configuration\n",
        "warnings.filterwarnings('ignore')\n",
        "st.set_page_config(page_title=\"Movie Recommender\", layout=\"wide\")\n",
        "\n",
        "\n",
        "\n",
        "# Load Data and Models\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    try:\n",
        "        dataset = load('/content/drive/My Drive/colab_data/finaldataset.pkl')\n",
        "        # Optimize memory usage\n",
        "        for col in ['plot_vector', 'genre_vector', 'metadata_vector', 'review_vector']:\n",
        "            if col in dataset:\n",
        "                dataset[col] = dataset[col].apply(lambda x: x.astype(np.float32))\n",
        "        return dataset\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading dataset: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    try:\n",
        "        model = load('/content/drive/My Drive/colab_data/logistic_model.pkl')\n",
        "        vectorizer = load('/content/drive/My Drive/colab_data/tfidf_vectorizer.pkl')\n",
        "        return model, vectorizer\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading models: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "# Initialize components\n",
        "dataset = load_data()\n",
        "model, vectorizer = load_models()\n",
        "\n",
        "# Recommendation Logic\n",
        "weights = {\n",
        "    'plot_vector': 0.3,\n",
        "    'genre_vector': 0.2,\n",
        "    'metadata_vector': 0.2,\n",
        "    'review_vector': 0.3\n",
        "}\n",
        "\n",
        "def compute_weighted_similarity(query_vector, candidate_vectors, weights):\n",
        "    similarities = []\n",
        "    for key in query_vector.keys():\n",
        "        sim = cosine_similarity(\n",
        "            query_vector[key].reshape(1, -1),\n",
        "            np.stack(candidate_vectors[key].values)\n",
        "        ).flatten()\n",
        "        similarities.append(weights[key] * sim)\n",
        "    return np.sum(similarities, axis=0)\n",
        "\n",
        "def get_recommendations(query_title, dataset, top_n=20):\n",
        "    movie_titles = dataset['title_x'].astype(str).tolist()\n",
        "\n",
        "    # Fixed extraction\n",
        "    result = process.extractOne(query_title, movie_titles, scorer=process.fuzz.ratio)\n",
        "    if not result:\n",
        "        return None, \"No matching movies found\"\n",
        "\n",
        "    closest_title, score = result\n",
        "\n",
        "    if score < 80:\n",
        "        return None, f\"Movie not found. Did you mean: '{closest_title}'?\"\n",
        "\n",
        "    query_row = dataset[dataset['title_x'].str.lower() == closest_title.lower()].iloc[0]\n",
        "\n",
        "    query_vector = {\n",
        "        'plot_vector': query_row['plot_vector'],\n",
        "        'genre_vector': query_row['genre_vector'],\n",
        "        'metadata_vector': query_row['metadata_vector'],\n",
        "        'review_vector': query_row['review_vector']\n",
        "    }\n",
        "    candidate_vectors = dataset[['plot_vector', 'genre_vector', 'metadata_vector', 'review_vector']]\n",
        "\n",
        "    similarity_scores = compute_weighted_similarity(query_vector, candidate_vectors, weights)\n",
        "    dataset['similarity_score'] = similarity_scores\n",
        "\n",
        "    top_movies = dataset[dataset['title_x'] != closest_title].nlargest(top_n, 'similarity_score').copy()\n",
        "\n",
        "    top_movies['review_text'] = top_movies['cleaned_reviews'].apply(\n",
        "        lambda x: \" \".join(x) if isinstance(x, list) else x if isinstance(x, str) else \"\")\n",
        "\n",
        "    review_vectors = vectorizer.transform(top_movies['review_text'])\n",
        "    top_movies['sentiment_score'] = model.predict_proba(review_vectors)[:, 1]\n",
        "    top_movies['final_score'] = top_movies['sentiment_score']*0.2 + top_movies['similarity_score']*0.8\n",
        "\n",
        "    return closest_title, top_movies.sort_values('final_score', ascending=False)\n",
        "# Streamlit UI\n",
        "st.title(\"ğŸ¬ Hybrid-Movie Recommender\")\n",
        "\n",
        "# Sidebar settings\n",
        "with st.sidebar:\n",
        "    st.header(\"Settings\")\n",
        "    top_n = st.slider(\"Number of recommendations\", 5, 20, 10)\n",
        "    show_details = st.checkbox(\"Show detailed scores\", True)\n",
        "\n",
        "# Main input\n",
        "query_title = st.text_input(\"Enter a movie you like:\", placeholder=\"E.g. Inception\")\n",
        "\n",
        "if query_title:\n",
        "    if dataset is None or model is None or vectorizer is None:\n",
        "        st.error(\"Failed to load required data or models. Please check your files.\")\n",
        "    else:\n",
        "        closest_title, recommendations = get_recommendations(query_title, dataset, top_n)\n",
        "\n",
        "        if recommendations is None:\n",
        "            st.warning(closest_title)\n",
        "        else:\n",
        "            st.success(f\"Found: **{closest_title}**\")\n",
        "\n",
        "            # Display recommendations\n",
        "            st.subheader(f\"Top {top_n} Recommendations\")\n",
        "            cols = ['title_x', 'similarity_score', 'sentiment_score', 'final_score'] if show_details else ['title_x']\n",
        "\n",
        "            st.dataframe(\n",
        "                recommendations[cols].rename(columns={'title_x': 'Title'}),\n",
        "                column_config={\n",
        "                    \"similarity_score\": st.column_config.NumberColumn(format=\"%.3f\"),\n",
        "                    \"sentiment_score\": st.column_config.NumberColumn(format=\"%.3f\"),\n",
        "                    \"final_score\": st.column_config.NumberColumn(format=\"%.3f\")\n",
        "                },\n",
        "                hide_index=True,\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "            # Visualize top recommendations\n",
        "            st.bar_chart(\n",
        "                recommendations.head(5).set_index('Title')[['SSscore']],\n",
        "                color=\"#FF4B4B\"\n",
        "            )\n",
        "''')\n",
        "\n",
        "# Run the app\n",
        "!streamlit run app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qwVwrTNfZjn",
        "outputId": "044353e8-bfa0-4981-a2c1-61d5c109ee46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.32.137.201"
          ]
        }
      ],
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0nv2SJighO6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc3EaUplXnW6"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpznIr9mqLcDNcgArdq7PZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}